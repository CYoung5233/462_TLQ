{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SAAF Notebook\n",
    "\n",
    "This Jupyter Notebook provides an interactive platform for FaaS development. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#\n",
    "# Welcome to the SAAF Jupyter notebook! This default notebook provides comments to guide you through\n",
    "# all of the main features. If you run into errors or problems please make sure you have the AWS CLI\n",
    "# properly configure so that you can deploy function with it, have Docker installed and running, gave \n",
    "# execute permission to everything in the /jupyter_workspace and /test directory, and finally\n",
    "# installed all the dependencies. You can use quickInstall.sh in the root folder to walk you through the\n",
    "# setup process and install dependencies.\n",
    "#\n",
    "# This first cell is just imports needed to setup the magic that goes on behind the scenes. \n",
    "# Run it and it should return nothing.\n",
    "#\n",
    "# Function available in jupyter_workspace/platforms/jupyter/interactive_helpers.py\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.realpath('..'))\n",
    "from platforms.jupyter.interactive_helpers import *\n",
    "\n",
    "# Configure your function details here. Currently the only thing you need is a lambda ARN to assign to functions.\n",
    "config = {\n",
    "    \"lambdaRoleARN\": \"FILL THIS IN\"\n",
    "}\n",
    "\n",
    "# If you want to disable automatic deployment across the entire notebook change this.\n",
    "setDeploy(True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Functions\n",
    "\n",
    "Any function with the @cloud_function decorator will be uploaded to the cloud. Define platforms and memory settings in the decorator. \n",
    "Functions are tested locally and must run sucessfully before being deployed."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#\n",
    "# Here is your first cloud function! Creating cloud functions is as simple as writing python functions with (request, context)\n",
    "# arguments and adding the @cloud_function decorator. Define the platform you would like to deploy to, the memory setting, and\n",
    "# pass your context object defined earlier. Other arguments like references, requirements, and containerize can be used. \n",
    "# They will be shown later.\n",
    "#\n",
    "# Cloud functions defined in this notebook do have a few limitations. The main one is that nothing outside the function\n",
    "# is deployed to the cloud. That is why imports are inside the function, which is a little weird and can have an\n",
    "# effect on what you can import. But for most things this is fine. \n",
    "#\n",
    "# Alongside deploying your function code, you can deploy files alongside this function by adding them to the\n",
    "# src/includes_{function name} folder (This function will use src/includes_hello_world). \n",
    "# This folder will be automatically created when the function is ran. You can include basically anything, files, scripts,\n",
    "# python libraries, whatever you need.\n",
    "#\n",
    "# If everything is setup correct, all you need to do is run this code block and you'll get a hello_world function\n",
    "# on AWS Lambda! If not all dependencies are installed you can use ./quickInstall.sh to download dependencies.\n",
    "#\n",
    "\n",
    "@cloud_function(platforms=[Platform.AWS], memory=256, config=config)\n",
    "def hello_world(request, context): \n",
    "    from Inspector import Inspector\n",
    "    inspector = Inspector()\n",
    "    inspector.inspectAll()\n",
    "    \n",
    "    inspector.addAttribute(\"message\", \"Hello from the cloud \" + str(request[\"name\"]) + \"!\") \n",
    "    \n",
    "    inspector.inspectAllDeltas()\n",
    "    return inspector.finish()\n",
    "\n",
    "result = test(function=hello_world, payload={\"name\": \"Bob\"}, config=config)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#\n",
    "# What if we want one cloud function to call another function? The cloud function decorator can do that for you automatically!\n",
    "# Simply add any cloud functions that this function calls to the references list. \n",
    "#\n",
    "# This function isn't cheating and just deploying both hello_world and jello_world together, both are deployed \n",
    "# as seperate functions and making requests to the other. This example isn't practical but all features\n",
    "# of python, such as multithreading, can be used to make multiple requests to functions in parallel.\n",
    "#\n",
    "# After running, see src/handler_jello_world.py for the automatically generated source code.\n",
    "#\n",
    "\n",
    "@cloud_function(platforms=[Platform.AWS], \n",
    "               memory=256, \n",
    "               config=config, \n",
    "               references=[hello_world])\n",
    "\n",
    "def jello_world(request, context): \n",
    "    from Inspector import Inspector\n",
    "    inspector = Inspector()\n",
    "    inspector.inspectAll()\n",
    "    \n",
    "    cloud_request = hello_world(request, None)\n",
    "    hello_message = cloud_request['message']\n",
    "    jello_message = hello_message.replace(\"Hello\", \"Jello\")\n",
    "    inspector.addAttribute(\"message\", jello_message)\n",
    "    \n",
    "    inspector.inspectAllDeltas()\n",
    "    return inspector.finish()\n",
    "\n",
    "result = test(function=jello_world, payload={\"name\": \"Bob\"}, config=config)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#\n",
    "# This function here requires the igraph dependency, you can see it defined in the requirements argument of the decorator.\n",
    "# Alongside that, this function will be deployed as a container isn't of zip function. Containers are built,\n",
    "# submitted to ECR, and deployed to AWS Lambda. For all function builds, you can see the generated files in \n",
    "# the /deploy directory. The complete build for this function will be in /deploy/graph_rank_container_aws_build where\n",
    "# you will be able to see all the python files, dependencies, and Dockerfile. \n",
    "#\n",
    "# This folder will be destroyed and recreated every time a function is deployed so it is not recommended to manually edit. \n",
    "# You can manually edit it and redeploy if it is really necessary.\n",
    "#\n",
    "@cloud_function(platforms=[Platform.AWS], memory=512, config=config, requirements=\"python-igraph\", containerize=True)\n",
    "def page_rank_container(request, context):\n",
    "    from Inspector import Inspector \n",
    "    import datetime\n",
    "    import igraph\n",
    "    import time\n",
    "    \n",
    "    inspector = Inspector()\n",
    "    inspector.inspectAll()\n",
    "    \n",
    "    size = request.get('size')\n",
    "    loops = request.get('loops')\n",
    "\n",
    "    for x in range(loops):\n",
    "        graph = igraph.Graph.Tree(size, 10)\n",
    "        result = graph.pagerank()\n",
    "\n",
    "    inspector.inspectAllDeltas()\n",
    "    return inspector.finish()\n",
    "\n",
    "result = test(function=page_rank_container, payload={\"size\": 100000, \"loops\": 50}, config=config)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Execute Experiments\n",
    "\n",
    "Use FaaS Runner to execute complex FaaS Experiments."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#\n",
    "# Now, what's cooler than running a function on the cloud once? Running it multiple times! The run_experiment\n",
    "# function allows you to create complex FaaS experiments. This function uses our FaaS Runner application\n",
    "# to execute functions behind the scenes. It's primary purpose is to run multiple function requests across many threads. \n",
    "# You define payloads in the payloads list, choose your memory setting (it will switch settings automatically)\n",
    "# and define how many runs you want to do, across how many threads, and how many times you want to repeat the test\n",
    "# with iterations. These are the most important parameters, but there are many more defined in the link below. \n",
    "#\n",
    "# After an experiment runs the results are converted into a pandas dataframe that you can continue using in this notebook. \n",
    "# For example you can use matplotlib to generate graphs (see below), or do any other form of data processing. \n",
    "#\n",
    "# This function provides a lot of utility and functionality but does have some minor limitations compared to the\n",
    "# actual FaaS Runner application.\n",
    "# 1. You only can define a single memory setting per experiment. Results will be lost if multiple are used.\n",
    "# 2. Categorization functionality is not included. It's functionality can be easily replicated.\n",
    "# 3. Experiment results are saved to /test/history/interactiveExperiment and are DELETED whenever run_experiment is called.\n",
    "#     If you would like to save experiment results permenantly back up that folder. \n",
    "#\n",
    "# Below are two different experiments for our functions. Execute them and generate graphs using the code cell below.\n",
    "# You now have experienced all the functionality of the SAAF Jupyter Workspace! Happy FaaS developing!\n",
    "#\n",
    "\n",
    "# Define experiment parameters. For more detail see: https://github.com/wlloyduw/SAAF/tree/master/test\n",
    "hello_experiment = {\n",
    "  \"payloads\": [{\"name\": \"Bob\"}],\n",
    "  \"memorySettings\": [256],\n",
    "  \"runs\": 25,\n",
    "  \"threads\": 5,\n",
    "  \"iterations\": 4,\n",
    "  \"warmupBuffer\": 0,\n",
    "  \"sleepTime\": 0,\n",
    "  \"randomSeed\": 42,\n",
    "  \"showAsList\": [],\n",
    "  \"showAsSum\": [\"newcontainer\"],\n",
    "  \"ignoreFromAll\": [\"zAll\", \"version\", \"linuxVersion\", \"hostname\"],\n",
    "  \"invalidators\": {},\n",
    "  \"removeDuplicateContainers\": False,\n",
    "  \"overlapFilter\": \"functionName\",\n",
    "  \"openCSV\": False\n",
    "}\n",
    "\n",
    "# Execute experiment\n",
    "hello_world_results = run_experiment(function=hello_world, platform=Platform.AWS, experiment=hello_experiment, config=config)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define experiment parameters. For more detail see: https://github.com/wlloyduw/SAAF/tree/master/test\n",
    "page_rank_experiment = {\n",
    "  \"payloads\": [{\"size\": 50000, \"loops\": 5},\n",
    "                {\"size\": 100000, \"loops\": 5},\n",
    "                {\"size\": 150000, \"loops\": 5}],\n",
    "  \"memorySettings\": [512],\n",
    "  \"runs\": 100,\n",
    "  \"threads\": 100,\n",
    "  \"iterations\": 2,\n",
    "  \"warmupBuffer\": 1,\n",
    "  \"sleepTime\": 0,\n",
    "  \"randomSeed\": 42,\n",
    "  \"showAsList\": [],\n",
    "  \"showAsSum\": [\"newcontainer\"],\n",
    "  \"ignoreFromAll\": [\"zAll\", \"version\", \"linuxVersion\", \"hostname\"],\n",
    "  \"invalidators\": {},\n",
    "  \"removeDuplicateContainers\": False,\n",
    "  \"overlapFilter\": \"functionName\",\n",
    "  \"openCSV\": True\n",
    "}\n",
    "\n",
    "# Execute experiment\n",
    "page_rank_results = run_experiment(function=page_rank_container, platform=Platform.AWS, experiment=page_rank_experiment, config=config)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Process Results\n",
    "\n",
    "FaaS Runner experiment results are parsed into a Pandas dataframe. This flexibility allows the ability to perform any kind of data processing that you would like."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import matplotlib and setup display.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Histogram of runtime\n",
    "plt.hist(hello_world_results['userRuntime'], 10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import matplotlib and setup display.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Histogram of runtime\n",
    "plt.hist(page_rank_results['userRuntime'], 10)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}